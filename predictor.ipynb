{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader,random_split,Subset\n",
    "from torchvision import datasets, transforms, models # add models to the list\n",
    "from torchvision.utils import make_grid\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ignore harmless warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "        transforms.RandomRotation(10),      # rotate +/- 10 degrees\n",
    "        transforms.RandomHorizontalFlip(),  # reverse 50% of images\n",
    "        transforms.Resize((224,224)),             # resize shortest side to 224 pixels      \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize with ImageNet stats\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "AlexNetmodel = models.alexnet(pretrained = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in AlexNetmodel.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "AlexNetmodel.classifier = nn.Sequential(nn.Linear(9216,1024),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Dropout(p=0.4),\n",
    "                                        nn.Linear(1024,5),\n",
    "                                        nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=9216, out_features=1024, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.4, inplace=False)\n",
       "    (3): Linear(in_features=1024, out_features=5, bias=True)\n",
       "    (4): LogSoftmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AlexNetmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AlexNetmodel.load_state_dict(torch.load('alex_model2.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'testing'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 55\u001b[0m\n\u001b[0;32m     52\u001b[0m                 \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWarning: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m predicted class index \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not valid.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Run the classification and moving function\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m classify_and_move_images()\n",
      "Cell \u001b[1;32mIn[16], line 27\u001b[0m, in \u001b[0;36mclassify_and_move_images\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclassify_and_move_images\u001b[39m():\n\u001b[1;32m---> 27\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m img_name \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(test_folder):\n\u001b[0;32m     28\u001b[0m         img_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(test_folder, img_name)\n\u001b[0;32m     30\u001b[0m         \u001b[38;5;66;03m# Check if it's an image file\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'testing'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Load the saved model\n",
    "AlexNetmodel.load_state_dict(torch.load('alex_model2.pth'))\n",
    "AlexNetmodel.eval()\n",
    "\n",
    "# Define the folder paths\n",
    "test_folder = 'testing'  # Replace with the path to your testing folder\n",
    "classified_folders = {\n",
    "    0: 'f16',\n",
    "    1: 'f22',\n",
    "    2: 'a10',\n",
    "    3: 'c130',\n",
    "    4: 'v22'\n",
    "}\n",
    "\n",
    "# Create the classified folders if they don't exist\n",
    "for folder in classified_folders.values():\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "# Function to classify and move images\n",
    "def classify_and_move_images():\n",
    "    for img_name in os.listdir(test_folder):\n",
    "        img_path = os.path.join(test_folder, img_name)\n",
    "        \n",
    "        # Check if it's an image file\n",
    "        if img_name.lower().endswith(('png', 'jpg', 'jpeg', 'bmp', 'gif')):\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            image = transform(image)\n",
    "            image = image.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "            # Predict the class\n",
    "            with torch.no_grad():\n",
    "                outputs = AlexNetmodel(image)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                class_idx = predicted.item()\n",
    "            \n",
    "            # Debug: Print the class index\n",
    "            print(f\"Predicted class index for {img_name}: {class_idx}\")\n",
    "\n",
    "            # Check if the predicted class index is valid\n",
    "            if class_idx in classified_folders:\n",
    "                # Move the image to the corresponding folder\n",
    "                target_folder = classified_folders[class_idx]\n",
    "                shutil.move(img_path, os.path.join(target_folder, img_name))\n",
    "                print(f\"Moved {img_name} to {target_folder}\")\n",
    "            else:\n",
    "                print(f\"Warning: {img_name} predicted class index {class_idx} is not valid.\")\n",
    "\n",
    "# Run the classification and moving function\n",
    "classify_and_move_images()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\dell/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2024-6-11 Python-3.11.5 torch-2.2.2 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'testing'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 83\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved annotated image to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mannotated_img_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# Run the detection and classification function\u001b[39;00m\n\u001b[1;32m---> 83\u001b[0m detect_and_classify_images()\n",
      "Cell \u001b[1;32mIn[17], line 38\u001b[0m, in \u001b[0;36mdetect_and_classify_images\u001b[1;34m()\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdetect_and_classify_images\u001b[39m():\n\u001b[1;32m---> 38\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m img_name \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(test_folder):\n\u001b[0;32m     39\u001b[0m         img_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(test_folder, img_name)\n\u001b[0;32m     41\u001b[0m         \u001b[38;5;66;03m# Check if it's an image file\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'testing'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Load YOLOv5 model\n",
    "yolo_model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "yolo_model.eval()\n",
    "\n",
    "# Load the classification model)\n",
    "AlexNetmodel.eval()\n",
    "\n",
    "# Define the image transformations for classification\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Define the folder paths\n",
    "test_folder = 'testing'  # Replace with the path to your testing folder\n",
    "output_folder = 'output'  # Folder to save annotated images\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Define the classification labels\n",
    "class_labels = {\n",
    "    0: 'a10',\n",
    "    1: 'c130',\n",
    "    2: 'f16',\n",
    "    3: 'f22',\n",
    "    4: 'v22'\n",
    "}\n",
    "\n",
    "# Function to detect and classify aircraft in images\n",
    "def detect_and_classify_images():\n",
    "    for img_name in os.listdir(test_folder):\n",
    "        img_path = os.path.join(test_folder, img_name)\n",
    "        \n",
    "        # Check if it's an image file\n",
    "        if img_name.lower().endswith(('png', 'jpg', 'jpeg', 'jfif', 'gif')):\n",
    "            # Open image using OpenCV\n",
    "            img_cv2 = cv2.imread(img_path)\n",
    "            img_pil = Image.fromarray(cv2.cvtColor(img_cv2, cv2.COLOR_BGR2RGB))\n",
    "            \n",
    "            # Detect objects in the image\n",
    "            results = yolo_model(img_cv2)\n",
    "            \n",
    "            # Convert results to DataFrame\n",
    "            results_df = results.pandas().xyxy[0]\n",
    "\n",
    "            # Process detections\n",
    "            draw = ImageDraw.Draw(img_pil)\n",
    "            font = ImageFont.load_default()\n",
    "\n",
    "            for index, row in results_df.iterrows():\n",
    "                if row['confidence'] > 0.5:  # Filter out low-confidence detections\n",
    "                    xmin, ymin, xmax, ymax = int(row['xmin']), int(row['ymin']), int(row['xmax']), int(row['ymax'])\n",
    "\n",
    "                    # Crop the detected region for classification\n",
    "                    cropped_image = img_pil.crop((xmin, ymin, xmax, ymax))\n",
    "                    cropped_image_tensor = transform(cropped_image).unsqueeze(0)\n",
    "\n",
    "                    # Classify the cropped region\n",
    "                    with torch.no_grad():\n",
    "                        outputs = AlexNetmodel(cropped_image_tensor)\n",
    "                        _, predicted = torch.max(outputs, 1)\n",
    "                        class_idx = predicted.item()\n",
    "\n",
    "                    # Draw the bounding box and label on the original image\n",
    "                    label = class_labels.get(class_idx, \"Unknown\")\n",
    "                    draw.rectangle(((xmin, ymin), (xmax, ymax)), outline=\"red\", width=2)\n",
    "                    draw.text((xmin, ymin - 10), label, fill=\"red\", font=font)\n",
    "                    print(f\"Detected and classified {label} in {img_name}\")\n",
    "\n",
    "            # Save the annotated image\n",
    "            annotated_img_path = os.path.join(output_folder, img_name)\n",
    "            img_pil.save(annotated_img_path)\n",
    "            print(f\"Saved annotated image to {annotated_img_path}\")\n",
    "\n",
    "# Run the detection and classification function\n",
    "detect_and_classify_images()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
